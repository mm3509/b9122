{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZCLZlIEysJW"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Import the required modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8CUNxcfyuYB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.linear_model\n",
        "import sklearn.neighbors\n",
        "import sklearn.neural_network\n",
        "\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcCXhWHOzthS"
      },
      "source": [
        "Initialize the random seed, for reproducibility, so we all get the same results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmlkEc3SzvsS"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D-NzdG1yXLe"
      },
      "source": [
        "## Data directory and Google Colab\n",
        "\n",
        "I write and run notebooks on Google Colab with data on Google Drive. This cell checks if the notebook is running on Google Colab. If so, it connects to Google Drive. Otherwise, it will look for the data in the current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFllBpV-wV5C"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "RUNNING_ON_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if RUNNING_ON_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DIR = \"drive/MyDrive\"\n",
        "else:\n",
        "  DIR = \".\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lxqE84JwZ2R"
      },
      "source": [
        "# Comparison of 3 classifiers with credit card transactions\n",
        "\n",
        "We have learned three classifiers in class:\n",
        "\n",
        "1. k-Nearest Neighbors (with majority voting, i.e. the prediction is the most common class among the k nearest neighbors);\n",
        "\n",
        "2. logistic regression (binomial / binary, or multinomial / multi-class);\n",
        "\n",
        "3. neural networks, or the multi-layer perceptron.\n",
        "\n",
        "Here, we estimate these three classifiers on a dataset of credit card transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAzn0fUAxsI5"
      },
      "source": [
        "## Data\n",
        "\n",
        "We use a publicly available dataset on [credit card transactions](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud). For privacy reasons, the explanatory variables (`V1-V28`) in this dataset are obfuscated (they come from \"dimensionality reduction\" via Principal Components Analysis, or PCA, and these are the most relevant factors). The other variables are the transaction amount and the label (1 for fraud, 0 for non-fraud). You need to unzip and extract the dataset in `creditcardfraud.zip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CJvvGGTziId"
      },
      "outputs": [],
      "source": [
        "DATA_FILEPATH = os.path.join(DIR, \"creditcard.csv\")\n",
        "df = pd.read_csv(DATA_FILEPATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rebalance the dataset, so that we have approximately the same number of legitimate and fraudulent transactions."
      ],
      "metadata": {
        "id": "fYt4yTU66s3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"Class\"]\n",
        "\n",
        "initial_shape = df.shape\n",
        "\n",
        "legitimate = df[y == 0]\n",
        "fraudulent = df[y == 1]\n",
        "\n",
        "legitimate = df.sample(n=fraudulent.shape[0], random_state=42)\n",
        "\n",
        "# Students: this line is the dataframe equivalent of list.extend().\n",
        "# The argument axis=0 ensures that we concatenate two dataframes vertically, by\n",
        "# adding rows (axis=1 would concatenate horizontally, adding columns).\n",
        "\n",
        "df = pd.concat([legitimate, fraudulent], axis=0)\n",
        "final_shape = df.shape\n",
        "\n",
        "print(f\"Rebalanced dataset from {initial_shape} to {final_shape}\")"
      ],
      "metadata": {
        "id": "FWHAuTTb6yoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8kA0SLTNF_X"
      },
      "source": [
        "## TODO: data check and summary statistics\n",
        "\n",
        "_The first thing to do with a new dataset is to check a few rows of the data and print summary statistics._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Vt5A9b_cec"
      },
      "source": [
        "## TODO: Plot the data\n",
        "\n",
        "_The second thing to do with a new dataset is to plot the data. If you want, you can use `legitimate` and `fraudulent` from the cell above, without having the subset the dataframe like we did in lecture._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB7uQFjeq8Ni"
      },
      "source": [
        "## TODO: Train-validation-test split: 60-20-20\n",
        "\n",
        "_Regarding the split numbers, the choice of 80-20 split is known as the Pareto Principle and you can read about it [here](https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPQZRtkXEi2b"
      },
      "source": [
        "## TODO: Logistic regression / classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ0Bw0qjE7tI"
      },
      "source": [
        "## TODO: k-Nearest Neighbors\n",
        "\n",
        "_Suggestion: use `k` in `[1, 5, 10, 50, 100]`._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxCYoAy7HfpW"
      },
      "source": [
        "## TODO: Neural networks\n",
        "\n",
        "_Suggestion: use the same hidden layers as in lecture: `[(20, 15), (20, 10), (15, 10), (20, 15, 10)]`._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9qlxherNwrC"
      },
      "source": [
        "## TODO: Comparison of the three classifiers on test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: summarize your findings\n",
        "\n",
        "_What patterns did you find in the data; what is the best classifier, and why?_"
      ],
      "metadata": {
        "id": "bQaPkyyoBEEa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}